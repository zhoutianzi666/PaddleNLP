FROM registry.baidubce.com/paddlepaddle/fastdeploy:llm-base-gcc12.3-cuda11.8-cudnn8-nccl2.15.5

WORKDIR /opt/output/
ENV LD_LIBRARY_PATH="/usr/local/cuda-11.8/compat/:$LD_LIBRARY_PATH"

RUN python3 -m pip install --pre paddlepaddle-gpu -i https://www.paddlepaddle.org.cn/packages/nightly/cu123/ \
    && python3 -m pip install paddlenlp==3.0.0b0 \
    && python3 -m pip install --no-cache-dir sentencepiece pycryptodome tritonclient[all]==2.41.1 \
    && python3 -m pip install --no-cache-dir --force-reinstall https://paddlepaddle-inference-banchmark.bj.bcebos.com/paddlenlp_ops-0.0.0-py3-none-any.whl \
    && apt-get clean && rm -rf /var/lib/apt/lists/*

RUN mkdir -p /opt/source/ && cd /opt/source/ \
    && git clone https://github.com/PaddlePaddle/Paddle.git \
    && git clone https://github.com/PaddlePaddle/PaddleNLP.git \
    && cp -r /opt/source/PaddleNLP/paddlenlp /usr/local/lib/python3.10/dist-packages/ \
    && python3 -m pip install --no-cache-dir -r PaddleNLP/requirements.txt \
    && python3 -m pip install --no-cache-dir -r PaddleNLP/llm/server/server/requirements.txt

RUN mkdir -p /opt/output/Serving/llm_model/model/1 \
    && cp /opt/source/PaddleNLP/llm/server/server/config/config.pbtxt /opt/output/Serving/llm_model/model/ \
    && cp /opt/source/PaddleNLP/llm/server/server/scripts/start_server.sh /opt/output/Serving/ \
    && cp /opt/source/PaddleNLP/llm/server/server/scripts/stop_server.sh /opt/output/Serving/

ENV PYTHONPATH="/opt/source/PaddleNLP/llm/server/server"
RUN echo "from server.triton_server import TritonPythonModel" >>/opt/output/Serving/llm_model/model/1/model.py

ENV http_proxy=""
ENV https_proxy=""
